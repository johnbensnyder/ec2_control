{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC2 Control\n",
    "\n",
    "This notebook demonstrates how to setup a single G4dn.8xlarge EC2 instance, and launch a Docker container running Juptyer Lab.\n",
    "\n",
    "Prerequisites: Before running this notebook, ensure that you have setup your AWS CLI credentials.\n",
    "\n",
    "### Read in configuration files\n",
    "\n",
    "Sample EC2 instance congfigurations are included in this repo under `docs/sample_configs`. Read in the G4dn.4x config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockDeviceMappings': [{'DeviceName': '/dev/sda1',\n",
      "                          'Ebs': {'VolumeSize': 1000, 'VolumeType': 'gp2'}}],\n",
      " 'ImageId': 'ami-078a7f1dda72c0775',\n",
      " 'InstanceType': 'g4dn.4xlarge',\n",
      " 'KeyName': 'your_keypair_name',\n",
      " 'MaxCount': 1,\n",
      " 'MinCount': 1,\n",
      " 'Monitoring': {'Enabled': False},\n",
      " 'Placement': {'AvailabilityZone': 'us-east-1b'},\n",
      " 'SecurityGroupIds': ['sg-your_security_group'],\n",
      " 'SubnetId': 'subnet-your_subnet',\n",
      " 'TagSpecifications': [{'ResourceType': 'instance',\n",
      "                        'Tags': [{'Key': 'Name',\n",
      "                                  'Value': 'some_name_for_your_instance'}]}]}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import pprint\n",
    "\n",
    "with open(\"../sample_configs/g4dn4x.yaml\") as in_config:\n",
    "    config = yaml.safe_load(in_config)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a few values still need to be filled in based on your own account. The keypair can be any previously created EC2 keypair. Subnet needs to be a subnet associated with the selected availability zone. This can be found on the EC2 setup page of the AWS console. Security group can be any number of security groups also found in the console. Finally, under tags give your instance any name you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['KeyName'] = 'keyname'\n",
    "config['SecurityGroupIds'] = ['some_security_group']\n",
    "config['TagSpecifications'][0]['Tags'][0]['Value'] = 'instance_name'\n",
    "config['SubnetId'] = 'subnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep these tools as transparent and extensible as possible, the EC2 Controls provided in this package are really just some wrappers to simplify already existing tools to work with instances. As much as possible, I try to directly use existing tools. Below, use Boto to launch your instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "ec2_session = boto3.Session(region_name=\"us-east-1\")\n",
    "ec2_client = ec2_session.client(\"ec2\")\n",
    "ec2_resource = ec2_session.resource(\"ec2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch instance\n",
    "response = ec2_client.run_instances(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the ec2_control ssh tool to communicate with the instance. First, we need to get the public ip address of the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ec2_control import ssh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [instance['InstanceId'] for instance in response['Instances']]\n",
    "status = ec2_resource.meta.client.describe_instances(InstanceIds=instances)\n",
    "public_ips = [instance['PublicIpAddress'] for instance in status['Reservations'][0]['Instances']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an ssh client.\n",
    "ssh_client = ssh.SSH(public_ips, '/root/.aws/keyfile.pem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'stderr': '',\n",
      "  'stdout': '00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC '\n",
      "            '[Natoma]\\n'\n",
      "            '00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA '\n",
      "            '[Natoma/Triton II]\\n'\n",
      "            '00:01.3 Non-VGA unclassified device: Intel Corporation '\n",
      "            '82371AB/EB/MB PIIX4 ACPI (rev 08)\\n'\n",
      "            '00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111\\n'\n",
      "            '00:04.0 Non-Volatile memory controller: Amazon.com, Inc. Device '\n",
      "            '8061\\n'\n",
      "            '00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network '\n",
      "            'Adapter (ENA)\\n'\n",
      "            '00:1e.0 3D controller: NVIDIA Corporation Device 1eb8 (rev a1)\\n'\n",
      "            '00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD '\n",
      "            'Controller\\n'}]\n"
     ]
    }
   ],
   "source": [
    "# test connection\n",
    "pci = ssh_client.run_on_all('lspci')\n",
    "pprint.pprint(pci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the above command uses `run_on_all`. The ssh client can send commands to multiple EC2 nodes at the same time. In this case, there is only one node, so `run_on_all` and `run_on_master` do the same thing. When dealing with multiple nodes, there is also the options to use `run_on_workers` or to send commands to specific nodes by using `run_on_node` and supplying the ip address of a specific node.\n",
    "\n",
    "In order to get data in and out of your instance, you need to supply it with some kind of AWS credentials associated with your account. This can be done on the instance itself by running `aws configure`. As a simple way to get started, here are the commands to pass your local credentials to the AWS cli configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read local credentials\n",
    "# paths might need to be adjusted (add Users at beginning of path on Mac)\n",
    "\n",
    "import getpass\n",
    "import configparser\n",
    "credentials = configparser.ConfigParser()\n",
    "credentials.read('/{0}/.aws/credentials'.format(getpass.getuser()))\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/{0}/.aws/config'.format(getpass.getuser()))\n",
    "\n",
    "# run AWS configure passing in access keys and secret\n",
    "ssh_client.run_on_all('aws configure set aws_access_key_id {}'.format(credentials['default']['aws_access_key_id']))\n",
    "ssh_client.run_on_all('aws configure set aws_secret_access_key {}'.format(credentials['default']['aws_secret_access_key']))\n",
    "ssh_client.run_on_all('aws configure set default.region {}'.format(config['default']['region']))\n",
    "\n",
    "# make sure to delete credentials so we don't accidently do something bad with them\n",
    "del credentials\n",
    "del config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The G4dn and P3dn instances include high speed NVME drives that can be useful when training neural nets that require high data throughput. Below we mount the drive to a directory called `shared_workspace` which we will later make available inside the Docker container.\n",
    "\n",
    "Note that this section is optional, but can be useful in some cases. However, also note that anything stored in NVME storaged will be deleted when the instance is stopped. So if you want this instance to maintain data for future use, it may be best to not use NVME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsblk = ssh_client.run_on_all('lsblk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'stderr': '',\n",
      "  'stdout': 'NAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\\n'\n",
      "            'loop0         7:0    0    18M  1 loop '\n",
      "            '/snap/amazon-ssm-agent/1566\\n'\n",
      "            'loop2         7:2    0  93.9M  1 loop /snap/core/9066\\n'\n",
      "            'loop3         7:3    0    97M  1 loop /snap/core/9289\\n'\n",
      "            'nvme0n1     259:0    0 209.6G  0 disk \\n'\n",
      "            'nvme1n1     259:1    0  1000G  0 disk \\n'\n",
      "            '└─nvme1n1p1 259:2    0  1000G  0 part /\\n'}]\n"
     ]
    }
   ],
   "source": [
    "#check the name of the drive we want to mount.\n",
    "pprint.pprint(lsblk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'stdout': '', 'stderr': ''}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nvme0n1 is not mounted, so that's the drive we'll use\n",
    "\n",
    "# create a directory\n",
    "ssh_client.run_on_all('mkdir -p ~/shared_workspace')\n",
    "\n",
    "# mount nvme0n1 to that directory\n",
    "# and give broad write and execute permissions\n",
    "# so it can be shared with docker\n",
    "ssh_client.run_on_all('sudo mkfs -t xfs /dev/nvme0n1')\n",
    "ssh_client.run_on_all('sudo mount /dev/nvme0n1 ~/shared_workspace')\n",
    "ssh_client.run_on_all('mkdir -p ~/shared_workspace/data')\n",
    "ssh_client.run_on_all('sudo chmod -R 777 ~/shared_workspace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you might want to do something like load data onto your drive for later use. One way is to pull data from S3 onto your instance. First, use s3fs to explore your S3 buckets and find the data you're interested in, then send the command to download to your node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3fs import S3FileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unless otherwise specified, s3fs will use\n",
    "# your default AWS credentials\n",
    "s3 = S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.ls('s3://some-bucket/data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'stdout': '', 'stderr': ''}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_command = \"aws s3 cp --recursive s3://some-bucket/data/train ~/shared_workspace/data\"\n",
    "ssh_client.run_on_all(\"mkdir ~/shared_workspace/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the ssh client will submit a command and wait for it to complete. When downloading data, we might not want to wait. By setting the option `wait=false` the ssh client will return a python thread that monitors the status of the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_download_thread = ssh_client.run_on_all(download_command, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included in this repo is a Dockerfile script to create a container that runs Jupyter Lab and includes a number of common Tensorflow development tools. The next few paragraphs deploys this Dockerfile to the instance and builds the container. If using another container, skip this section.\n",
    "\n",
    "Two notes about the lines below, the `scp_local_to_master` copies local files to the master node. As with the `run_on_...` commands, this can be used to interface with master, worker, or all nodes. There is also a tool to copy to local from nodes.\n",
    "\n",
    "Second, we copy `/opt/amazon/efa` into the docker directory. This directory contains the EFA drivers for using the high speed EFA interconnect between nodes. While this feature is not available on G4dn nodes, it's worth adding to the docker image, in case this image is later used on a P3dn or similar node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerhub_user = 'your dockerhub user name'\n",
    "dockerhub_repo = 'ec2_notebook'\n",
    "dockerhub_tag = 'tutorial'\n",
    "\n",
    "ssh_client.scp_local_to_master('../docker', 'docker', recursive=True)\n",
    "ssh_client.run_on_master('cp -R /opt/amazon/efa docker/')\n",
    "ssh_client.run_on_master('cd docker && docker build -t {}/{}:{} .'.format(dockerhub_user,\n",
    "                                                                          dockerhub_repo,\n",
    "                                                                          dockerhub_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TerminatingInstances': [{'CurrentState': {'Code': 32,\n",
       "    'Name': 'shutting-down'},\n",
       "   'InstanceId': 'i-02acc8f01fbaa06ad',\n",
       "   'PreviousState': {'Code': 16, 'Name': 'running'}}],\n",
       " 'ResponseMetadata': {'RequestId': '61284b4a-0350-4ca3-890a-09d5f58ba6d4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '61284b4a-0350-4ca3-890a-09d5f58ba6d4',\n",
       "   'content-type': 'text/xml;charset=UTF-8',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'vary': 'accept-encoding',\n",
       "   'date': 'Fri, 12 Jun 2020 01:57:12 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec2_client.terminate_instances(InstanceIds=instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
